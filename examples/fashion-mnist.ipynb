{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdc69b41-51f3-48f9-89f6-933bd5310157",
   "metadata": {},
   "source": [
    "Fully Homomorphically Encrypted Fashion-MNIST CNN Example\n",
    "=========================================================\n",
    "\n",
    "- This example will download Fashion-MNIST (a drop in replacement for MNIST)\n",
    "- Prepare Fashion-MNIST\n",
    "- Train a very basic CNN on Fashion-MNIST in plaintext\n",
    "- Infer using the testing set using both plaintexts and cyphertexts for comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8c2f4a-b990-4909-999a-be6545483087",
   "metadata": {},
   "source": [
    "Download Fashion-MNIST\n",
    "----------------------\n",
    "\n",
    "- Get Fashion-MNIST as a zipped up set of CSVs\n",
    "- Unizp Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365eada6-e664-4e31-a44a-0b6df5e80c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pyvis seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eabf22f-ba77-470b-a139-f1bad38c26e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import logging\n",
    "import time\n",
    "import datetime\n",
    "import copy\n",
    "import seaborn as sns\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "# logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f0a8e2-6f34-45d8-935d-d4d1a23a0b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd() # current working directory\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e21c5e-b896-48d1-9808-8c9c0f999581",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(cwd, \"datasets\")\n",
    "if os.path.exists(data_dir):\n",
    "    pass\n",
    "else:\n",
    "    os.mkdir(data_dir)\n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103176f2-a7c4-463e-8403-354db1316d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_zip = os.path.join(data_dir, \"mnist.zip\")\n",
    "if os.path.exists(mnist_zip):\n",
    "    print(\"Skipping mnist download\")\n",
    "else:\n",
    "    print(\"Downloading Fashion-MNIST\")\n",
    "    mnist_url = \"http://nextcloud.deepcypher.me/s/wjLa6YFw8Bcbra9/download\"\n",
    "    r = requests.get(mnist_url, allow_redirects=True, verify=False)\n",
    "    with open(mnist_zip, \"wb\") as f:\n",
    "        f.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4d5a3a-bc16-4f87-b3c7-65524a8a59a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "unzip_dir = os.path.join(data_dir, \"mnist\")\n",
    "if os.path.exists(unzip_dir):\n",
    "    pass\n",
    "else:\n",
    "    os.mkdir(unzip_dir)\n",
    "with zipfile.ZipFile(mnist_zip, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(unzip_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4abd62-426a-4abf-a205-9c5cf1a696ff",
   "metadata": {},
   "source": [
    "\"Wrangle\"/ prepare Fashion-MNIST\n",
    "--------------------------------\n",
    "\n",
    "- Read in the Fashion-MNIST CSVs\n",
    "- Split training and testing features (x) from target (y)\n",
    "- Normalise x and y (in the range 0-1 to prevent infinite numbers when using our approximations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d89550-ef22-4ee0-a041-7e23382f7542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1339b61a-a11c-4123-90ea-47a336535cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = os.path.join(unzip_dir, \"fashion-mnist_train.csv\") \n",
    "test_file = os.path.join(unzip_dir, \"fashion-mnist_test.csv\")\n",
    "train = pd.read_csv(train_file)\n",
    "test = pd.read_csv(test_file)\n",
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48e0390-8ae5-48ad-9fa6-f1aac6c40d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train.iloc[:, 0]\n",
    "train_x = train.iloc[:, 1:]/255 # normalise to 0-1 preventing explosion\n",
    "test_x = test.iloc[:, 1:]/255 # normalise to 0-1 preventing explosion\n",
    "test_y = test.iloc[:, 0]\n",
    "train_x = train_x.to_numpy()\n",
    "train_y = train_y.to_numpy()\n",
    "test_x = test_x.to_numpy()\n",
    "test_y = test_y.to_numpy()\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1efcad-b224-4552-ae64-d0d0d75d4470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee411b28-1845-4f98-9d12-5a59918d71fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7881169-0cf8-4379-968a-ee3eece51ca4",
   "metadata": {},
   "source": [
    "Define Neural Network\n",
    "---------------------\n",
    "\n",
    "- Use [Networkx](https://networkx.org/) to construct a **multi-directed-graph** as a neural network\n",
    "- Nodes for this graph are abstractions of neural network components with forward, backward (backpropogation), update (weight update/ optimisation), and costs (computational depth of traversal to the node)\n",
    "- We use Nodes that inherit from the abstract base class [fhez.nn.graph.node.Node](https://python-fhez.readthedocs.io/en/latest/nodes/node.html#node) so if you need to define your own type of node inherit from this to match the API the network traverser expects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6051a6b2-6348-42b3-99a4-e4fcba385044",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from fhez.nn.graph.prefab import orbweaver\n",
    "graph = orbweaver()\n",
    "print(graph) # you can modify this graph like any other networkx graph using our existing/ ready made nodes like adding a new CNN layer for instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d1b41d-17fc-4012-bbe7-ea46662a755f",
   "metadata": {},
   "source": [
    "Visualise the graph\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dae6dd9-2c95-4395-ac9d-7bab2c481b93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pyvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd81dbb-146d-404e-9b0c-225c8d14d4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def strip(graph):\n",
    "    g = copy.deepcopy(graph)\n",
    "    for node in g.nodes(data=True):\n",
    "        try:\n",
    "            # node[1][\"title\"] = \"{}:\\n{}\".format(type(node[1][\"node\"]), repr(node[1][\"node\"]))\n",
    "            del node[1][\"node\"]\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return g\n",
    "    \n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1975a72e-7dd0-4ec6-a982-4cadc40728d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "stripped = strip(graph)\n",
    "print(stripped)\n",
    "\n",
    "from pyvis.network import Network\n",
    "net = Network('700px', '700px', bgcolor='#222222', font_color='white', notebook=True)\n",
    "net.from_nx(stripped)\n",
    "# net.show_buttons(filter_=\"physics\")\n",
    "net.show(\"graph.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a89daf0-2be7-4f85-823e-25635a430045",
   "metadata": {},
   "source": [
    "Train Using Plaintext Data\n",
    "--------------------------\n",
    "\n",
    "- Instantiate our neural networks\n",
    "- Compute the forward pass of our neural networks\n",
    "- Compute the backward pass of our neural networks\n",
    "\n",
    "I would like to stress that FHE is not a panacea.\n",
    "You may be wondering, why dont we train the neural network using cyphertexts? The simple answer is, *where/ when do we stop?*\n",
    "This statement refers to two *stops* in particular, when do we stop the training when we cannot see the loss, and where does the cyphertext *stop* for instance do we carry the cyphertext all the way through which means our neural network weights are encrypted.\n",
    "The solution to the first *stop* is both simple but expensive, the answer is we compute the training-test divergence on the client side where the keys exist so that we can find the optimal *training stop* point but this requires us to have a continued connection to the client.\n",
    "There are many answers to when we might figurativeley stop the cyphertext, but if privacy is of pivital concern then the only real answer is never, since any plaintext weights could be used in theorey to reconstruct the data that was used to train it, which means if we do the forward pass in cyphertext but do the backward pass in plaintext we dont gain any privacy since the data is then known to the data processor. However if we stick to cyphertexts throught all the way upto and including the weight update that means naturally when the weights are updated by the gradients which themselves come from the inputs thus all cyphertexts, that the weights after the first iteration of the network will become encrypted, taking *significantly* (orders of magnitude) longer to calculate since cyphertext + cyphertext operations take much longer even than cyphertext + plaintext calculations. This is not to mention the lack of compatibility of loss functions with FHE since many require some form of division which must be approximated.\n",
    "\n",
    "Thus we think the optimal solution is actually transfer learning. Where you train on a similar dataset and try to transfer the understanding to a similar problem, but infer using cyphertexts only. That way privacy is maintained since the plaintext weights are untouched by the clients data, and we can still create encrypted inference albeit with lower accuracy, but not incurring the cyphertext-cyphertext cost of encrypted weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3b2abc-0d26-4264-b433-5541bdd7fe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fhez.nn.graph.utils import train, infer\n",
    "from fhez.nn.loss.cce import CCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cce10b9-0882-4218-a92a-196b3d0a206a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn = Layer_CNN(weights=( 1, 6, 6 ), stride=[ 1, 4, 4 ], bias=0)\n",
    "# dense = None\n",
    "# for cyphertext in row_encrypted_generator(data=train_x, shape=( 1, 28, 28 )):\n",
    "#     cnn_acti = cnn.forward(cyphertext)\n",
    "#     if dense is None:\n",
    "#         dense = Layer_ANN(weights=(len(cnn_acti),), bias=0)\n",
    "#     dense.forward(cnn_acti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593fc831-c4b6-462e-8a91-13cf9ce41c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = {\n",
    "        \"x\": [],\n",
    "        \"y\": [],\n",
    "    }\n",
    "\n",
    "for i in zip(train_x, train_y):\n",
    "    train_dict[\"x\"].append(np.reshape(i[0], (28,28)))\n",
    "    train_dict[\"y\"].append(i[1])\n",
    "    \n",
    "# # for i in train_x:\n",
    "# #     train_dict[\"x\"].append(np.reshape(i, (28, 28)))\n",
    "    \n",
    "# print(train_y, type(train_y), train_y.shape)\n",
    "# print(train_x, type(train_x), train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0738287-8887-45a7-a407-31ec569e87df",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = time.time()\n",
    "output = train(graph=graph, inputs=train_dict, batch_size=5, debug=False)\n",
    "tt = time.time() - tt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb547132-0ef1-4106-b25b-657a540cf25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_graph = copy.deepcopy(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b1f1e9-2973-4fce-a50b-147daec01bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9beec1-5912-4ec3-9de1-504f0b9a8df9",
   "metadata": {},
   "source": [
    "Plaintext Inference\n",
    "-------------------\n",
    "\n",
    "- Find accuracy against testing set in plaintext space for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecedd124-bced-4836-bdab-81facc5d604a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = {\n",
    "        \"x\": [],\n",
    "        \"y\": [],\n",
    "    }\n",
    "for i in zip(test_x, test_y):\n",
    "    test_dict[\"x\"].append(np.reshape(i[0], (28,28)))\n",
    "    test_dict[\"y\"].append(i[1])\n",
    "    \n",
    "pi = time.time()\n",
    "y_hats = infer(graph=graph, inputs={key:value for key,value in test_dict.items() if key in [\"x\"]})[\"y_hat\"] \n",
    "pi = time.time() - pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15f6577-df35-49fa-896f-7b2f1199b0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=y_hats[20:40]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cec962-1192-4905-91b5-9663e16c4295",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_sample = test_dict[\"y\"][20:40]\n",
    "true_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bff23e7-b5da-4af2-b47a-98b07f0f2c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accurates = np.where(np.isclose(y_hats, test_dict[\"y\"]))\n",
    "len(accurates[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844bc996-4741-45d8-beeb-4357e4be4e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = len(accurates[0])/len(test_dict[\"y\"])\n",
    "print(\"Accuracy {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d74cd47-e200-4371-a9de-854fc032cd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"fashion_MNIST_results.csv\"\n",
    "current_result = pd.DataFrame({\"accuracy\": [accuracy], \n",
    "                               \"training_time\": [tt], \n",
    "                               \"plain_inference_time\": [pi], \n",
    "                               \"datetime\": [datetime.datetime.now()], \n",
    "                               \"y_hat_sample\": [sample], \n",
    "                               \"y_sample\": [true_sample], \n",
    "                               \"inference_size\": [len(test_dict[\"y\"])],\n",
    "                               \"activation\": [\"ReLU\"],\n",
    "                              })\n",
    "try:\n",
    "    all_results = pd.read_csv(csv_path, index_col=False)\n",
    "    all_results[\"activation\"] = \"ReLU\"\n",
    "    all_results = all_results.append(current_result)\n",
    "except FileNotFoundError:\n",
    "    all_results = current_result\n",
    "all_results.to_csv(csv_path, index=False)\n",
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3056e0-f5b5-4a25-9828-6a6a8444a6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(y=\"accuracy\", x=\"activation\", data=all_results)\n",
    "ax = sns.swarmplot(y=\"accuracy\", x=\"activation\", data=all_results, color=\".25\")\n",
    "ax.set(title=\"Model Accuracy by Activation\")\n",
    "fig = ax.get_figure()\n",
    "fig.savefig(\"fashion-mnist-swarm.png\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a9ec5b-d48d-442b-ae63-6fd60e9db055",
   "metadata": {},
   "source": [
    "Not great, not terrible (3.6 roentgen). Absolute network performance can always be improved by using newer/ better architectures, and more epochs if it has not learnt what it can from the training set. we use a simple 1 CNN layer + 10 Dense layers + softmax into categorical cross entropy, there are much better architectures to use but we are concerned with the encryption here so we dont want to overcomplicate things. This is more of a means to an end of comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f59c1c-cbec-4ce3-bf21-87d0ad1e7663",
   "metadata": {},
   "source": [
    "Encrypted Inference\n",
    "-------------------\n",
    "\n",
    "- find accuracy against testing set again but this time in encrypted space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1c4660-517d-48be-bec4-fe579f0dc385",
   "metadata": {},
   "source": [
    "Parameterise Encoding/ Encryption and Create an Encrypted Generator\n",
    "-------------------------------------------------------------------\n",
    "\n",
    "- Parameterise our neural network graph encryption nodes\n",
    "- Automatically set parameterisation using AtoFHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f740fa97-b6a5-49e3-834e-a649b37973df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seal\n",
    "encryption_parameters = {\n",
    "            \"scheme\": seal.scheme_type.CKKS,\n",
    "            \"poly_modulus_degree\": 8192*2,\n",
    "            \"coefficient_modulus\":\n",
    "                [45, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 45],\n",
    "            \"scale\": pow(2.0, 30),\n",
    "            \"cache\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f5efb5-2e32-4ae1-bb44-cbcfc5d0ccf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate Encrypted data peace-meal (as it can get very large)\n",
    "# def row_encrypted_generator(data: np.ndarray, shape: tuple):\n",
    "#     \"\"\"Generate encrypted data of desired shape from rows.\"\"\"\n",
    "#     for row in data:\n",
    "#         row = np.reshape(row, newshape=shape) / 255 # reshape to image shape and normalise between 0-1\n",
    "#         yield ReArray(row, **encryption_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653474d9-c3a4-4bcc-8e91-8afcc2e01e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
