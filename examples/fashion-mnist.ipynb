{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdc69b41-51f3-48f9-89f6-933bd5310157",
   "metadata": {},
   "source": [
    "Fully Homomorphically Encrypted Fashion-MNIST CNN Example\n",
    "=========================================================\n",
    "\n",
    "- This example will download Fashion-MNIST (a drop in replacement for MNIST)\n",
    "- Prepare Fashion-MNIST\n",
    "- Train a very basic CNN on Fashion-MNIST in plaintext\n",
    "- Infer using the testing set using both plaintexts and cyphertexts for comparison\n",
    "\n",
    ".. warning:\n",
    "\n",
    "    The encrypted forward pass is VERY RAM HUNGRY! Keep a close eye on your RAM usage in case it exceeds your machines capabilities. In some scenarios it may be desirable to have a SWAP partition on the fastest storage you have avaliable. We are working on getting the RAM usage down! FHE on anything is very space and compute intensive, but we do have inefficiencies we could minimise too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c548872-5f91-49b9-b2c4-06cfcc0fa8fe",
   "metadata": {},
   "source": [
    "# Basic Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365eada6-e664-4e31-a44a-0b6df5e80c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pyvis seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eabf22f-ba77-470b-a139-f1bad38c26e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import logging\n",
    "import time\n",
    "import datetime\n",
    "import copy\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "# logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd763b1c-07b4-40c6-a2b2-c5fc926d2fd0",
   "metadata": {},
   "source": [
    "# Display our pre-existing findings\n",
    "\n",
    "(Skip this section if you have deleted our existing results and are thus starting from scratch)\n",
    "\n",
    "In this section we will output some graphs to show our existing findings in fashion_MNIST_results.csv. This Jupyter notebook will append more results when run to this CSV file so you can also use this to show your new results when you run this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba348caa-8a1c-4400-85dc-0beaa69154ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"fashion_MNIST_results.csv\"\n",
    "all_results = pd.read_csv(csv_path, index_col=False)\n",
    "all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd0df29-9372-462f-aa56-e6f598d6141c",
   "metadata": {},
   "source": [
    "A few minor fixes to the table from older versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d1ec6a-43fa-4951-bf0b-09aef909d659",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fill_dict = {\"activation\": \"ReLU\", \"is_plaintext\": 1.0, \"is_cyphertext\": 0, }\n",
    "all_results = all_results.fillna(value=fill_dict)\n",
    "try:\n",
    "    all_results[\"time_taken\"].fillna(all_results[\"plain_inference_time\"], inplace=True) # move values from old column to new\n",
    "    del all_results[\"plain_inference_time\"]\n",
    "except KeyError:\n",
    "    pass # ok not dealing with an old version\n",
    "all_results.loc[all_results[\"is_plaintext\"] == 1, \"dtype\"] = \"plaintext\"\n",
    "all_results = all_results.fillna(value={\"dtype\": \"cyphertext\"})\n",
    "all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96494bf1-2aff-4082-a209-6d0d8c89e85c",
   "metadata": {},
   "source": [
    "## Plot the performance of the neural networks by activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b771f5b-22f0-4e38-b9f0-1797d9b51305",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(y=\"accuracy\", x=\"activation\", data=all_results)\n",
    "ax = sns.swarmplot(y=\"accuracy\", x=\"activation\", data=all_results, color=\".25\")\n",
    "ax.set(title=\"Model Accuracy by Activation\")\n",
    "fig = ax.get_figure()\n",
    "fig.savefig(\"sphira-fashion-mnist-performance.png\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0939a87-b8e0-4ef5-9695-b102b22744e6",
   "metadata": {},
   "source": [
    "## Plot the time taken by plaintexts and cyphertexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f8a67a-348f-4a50-bfc4-5eef70b744a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(y=\"time_taken\", x=\"dtype\", data=all_results)\n",
    "ax = sns.swarmplot(y=\"time_taken\", x=\"dtype\", data=all_results, color=\".25\")\n",
    "ax.set(title=\"Time Taken by Data Type\", ylabel=\"Inference Time (s)\", xlabel=\"Data Type\")\n",
    "fig = ax.get_figure()\n",
    "fig.savefig(\"sphira-fashion-mnist-inference-time.png\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8c2f4a-b990-4909-999a-be6545483087",
   "metadata": {
    "tags": []
   },
   "source": [
    "Download Fashion-MNIST\n",
    "----------------------\n",
    "\n",
    "- Get Fashion-MNIST as a zipped up set of CSVs\n",
    "- Unizp Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f0a8e2-6f34-45d8-935d-d4d1a23a0b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd() # current working directory\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e21c5e-b896-48d1-9808-8c9c0f999581",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(cwd, \"datasets\")\n",
    "if os.path.exists(data_dir):\n",
    "    pass\n",
    "else:\n",
    "    os.mkdir(data_dir)\n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103176f2-a7c4-463e-8403-354db1316d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_zip = os.path.join(data_dir, \"mnist.zip\")\n",
    "if os.path.exists(mnist_zip):\n",
    "    print(\"Skipping mnist download\")\n",
    "else:\n",
    "    print(\"Downloading Fashion-MNIST\")\n",
    "    mnist_url = \"http://nextcloud.deepcypher.me/s/wjLa6YFw8Bcbra9/download\"\n",
    "    r = requests.get(mnist_url, allow_redirects=True, verify=False)\n",
    "    with open(mnist_zip, \"wb\") as f:\n",
    "        f.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4d5a3a-bc16-4f87-b3c7-65524a8a59a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "unzip_dir = os.path.join(data_dir, \"mnist\")\n",
    "if os.path.exists(unzip_dir):\n",
    "    pass\n",
    "else:\n",
    "    os.mkdir(unzip_dir)\n",
    "with zipfile.ZipFile(mnist_zip, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(unzip_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4abd62-426a-4abf-a205-9c5cf1a696ff",
   "metadata": {},
   "source": [
    "\"Wrangle\"/ prepare Fashion-MNIST\n",
    "--------------------------------\n",
    "\n",
    "- Read in the Fashion-MNIST CSVs\n",
    "- Split training and testing features (x) from target (y)\n",
    "- Normalise x and y (in the range 0-1 to prevent infinite numbers when using our approximations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d89550-ef22-4ee0-a041-7e23382f7542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1339b61a-a11c-4123-90ea-47a336535cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = os.path.join(unzip_dir, \"fashion-mnist_train.csv\") \n",
    "test_file = os.path.join(unzip_dir, \"fashion-mnist_test.csv\")\n",
    "train = pd.read_csv(train_file)\n",
    "test = pd.read_csv(test_file)\n",
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48e0390-8ae5-48ad-9fa6-f1aac6c40d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train.iloc[:, 0]\n",
    "train_x = train.iloc[:, 1:]/255 # normalise to 0-1 preventing explosion\n",
    "test_x = test.iloc[:, 1:]/255 # normalise to 0-1 preventing explosion\n",
    "test_y = test.iloc[:, 0]\n",
    "train_x = train_x.to_numpy()\n",
    "train_y = train_y.to_numpy()\n",
    "test_x = test_x.to_numpy()\n",
    "test_y = test_y.to_numpy()\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1efcad-b224-4552-ae64-d0d0d75d4470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee411b28-1845-4f98-9d12-5a59918d71fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7881169-0cf8-4379-968a-ee3eece51ca4",
   "metadata": {},
   "source": [
    "Define Neural Network\n",
    "---------------------\n",
    "\n",
    "- Use [Networkx](https://networkx.org/) to construct a **multi-directed-graph** as a neural network\n",
    "- Nodes for this graph are abstractions of neural network components with forward, backward (backpropogation), update (weight update/ optimisation), and costs (computational depth of traversal to the node)\n",
    "- We use Nodes that inherit from the abstract base class [fhez.nn.graph.node.Node](https://python-fhez.readthedocs.io/en/latest/nodes/node.html#node) so if you need to define your own type of node inherit from this to match the API the network traverser expects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6051a6b2-6348-42b3-99a4-e4fcba385044",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from fhez.nn.graph.prefab import sphira\n",
    "from fhez.nn.activation.sigmoid import Sigmoid\n",
    "graph = sphira()\n",
    "print(graph) # you can modify this graph like any other networkx graph using our existing/ ready made nodes like adding a new CNN layer for instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b091e20c-b707-4eaf-a032-1a46d4b872e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # optionally modify the graph\n",
    "# # here we replace RELU with sigmoid activation for comparison only, ReLU is almost certainly better\n",
    "from fhez.nn.activation.sigmoid import Sigmoid\n",
    "graph.nodes(data=True)[\"CNN-RELU\"][\"node\"] = Sigmoid()\n",
    "print(graph.nodes(data=True)[\"CNN-RELU\"])\n",
    "for i in range(10):\n",
    "    graph.nodes(data=True)[\"Dense-RELU-{}\".format(i)][\"node\"] = Sigmoid()\n",
    "    print(graph.nodes(data=True)[\"Dense-RELU-{}\".format(i)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d1b41d-17fc-4012-bbe7-ea46662a755f",
   "metadata": {},
   "source": [
    "Visualise the graph\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd81dbb-146d-404e-9b0c-225c8d14d4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def strip(graph):\n",
    "    g = copy.deepcopy(graph)\n",
    "    for node in g.nodes(data=True):\n",
    "        try:\n",
    "            # node[1][\"title\"] = \"{}:\\n{}\".format(type(node[1][\"node\"]), repr(node[1][\"node\"]))\n",
    "            del node[1][\"node\"]\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return g\n",
    "    \n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1975a72e-7dd0-4ec6-a982-4cadc40728d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "stripped = strip(graph)\n",
    "print(stripped)\n",
    "\n",
    "from pyvis.network import Network\n",
    "net = Network('700px', '700px', bgcolor='#222222', font_color='white', notebook=True)\n",
    "net.from_nx(stripped)\n",
    "# net.show_buttons(filter_=\"physics\")\n",
    "net.show(\"graph.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a89daf0-2be7-4f85-823e-25635a430045",
   "metadata": {},
   "source": [
    "Train Using Plaintext Data\n",
    "--------------------------\n",
    "\n",
    "- Instantiate our neural networks\n",
    "- Compute the forward pass of our neural networks\n",
    "- Compute the backward pass of our neural networks\n",
    "\n",
    "I would like to stress that FHE is not a panacea.\n",
    "You may be wondering, why dont we train the neural network using cyphertexts? The simple answer is, *where/ when do we stop?*\n",
    "This statement refers to two *stops* in particular, when do we stop the training when we cannot see the loss, and where does the cyphertext *stop* for instance do we carry the cyphertext all the way through which means our neural network weights are encrypted.\n",
    "The solution to the first *stop* is both simple but expensive, the answer is we compute the training-test divergence on the client side where the keys exist so that we can find the optimal *training stop* point but this requires us to have a continued connection to the client.\n",
    "There are many answers to when we might figurativeley stop the cyphertext, but if privacy is of pivital concern then the only real answer is never, since any plaintext weights could be used in theorey to reconstruct the data that was used to train it, which means if we do the forward pass in cyphertext but do the backward pass in plaintext we dont gain any privacy since the data is then known to the data processor. However if we stick to cyphertexts throught all the way upto and including the weight update that means naturally when the weights are updated by the gradients which themselves come from the inputs thus all cyphertexts, that the weights after the first iteration of the network will become encrypted, taking *significantly* (orders of magnitude) longer to calculate since cyphertext + cyphertext operations take much longer even than cyphertext + plaintext calculations. This is not to mention the lack of compatibility of loss functions with FHE since many require some form of division which must be approximated.\n",
    "\n",
    "Thus we think the optimal solution is actually transfer learning. Where you train on a similar dataset and try to transfer the understanding to a similar problem, but infer using cyphertexts only. That way privacy is maintained since the plaintext weights are untouched by the clients data, and we can still create encrypted inference albeit with lower accuracy, but not incurring the cyphertext-cyphertext cost of encrypted weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3b2abc-0d26-4264-b433-5541bdd7fe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fhez.nn.graph.utils import train, infer\n",
    "from fhez.nn.loss.cce import CCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cce10b9-0882-4218-a92a-196b3d0a206a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn = Layer_CNN(weights=( 1, 6, 6 ), stride=[ 1, 4, 4 ], bias=0)\n",
    "# dense = None\n",
    "# for cyphertext in row_encrypted_generator(data=train_x, shape=( 1, 28, 28 )):\n",
    "#     cnn_acti = cnn.forward(cyphertext)\n",
    "#     if dense is None:\n",
    "#         dense = Layer_ANN(weights=(len(cnn_acti),), bias=0)\n",
    "#     dense.forward(cnn_acti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593fc831-c4b6-462e-8a91-13cf9ce41c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = {\n",
    "        \"x\": [],\n",
    "        \"y\": [],\n",
    "    }\n",
    "\n",
    "for i in zip(train_x, train_y):\n",
    "    train_dict[\"x\"].append(np.reshape(i[0], (28,28)))\n",
    "    train_dict[\"y\"].append(i[1])\n",
    "    \n",
    "# # for i in train_x:\n",
    "# #     train_dict[\"x\"].append(np.reshape(i, (28, 28)))\n",
    "    \n",
    "# print(train_y, type(train_y), train_y.shape)\n",
    "# print(train_x, type(train_x), train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0738287-8887-45a7-a407-31ec569e87df",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = time.time()\n",
    "output = train(graph=graph, inputs=train_dict, batch_size=5, debug=False)\n",
    "tt = time.time() - tt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb547132-0ef1-4106-b25b-657a540cf25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_graph = copy.deepcopy(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04eeb2d-c59f-4147-85bb-16b3f72f52a1",
   "metadata": {},
   "source": [
    "now that a graph has been trained let us mark it with a unique session reference just so when we save it in the CSV it is easier to find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8e87c6-ed9d-4146-9a60-89184e02483d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, string\n",
    "session = ''.join(random.choice(string.ascii_uppercase + string.ascii_lowercase + string.digits) for _ in range(6))\n",
    "session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b1f1e9-2973-4fce-a50b-147daec01bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9beec1-5912-4ec3-9de1-504f0b9a8df9",
   "metadata": {},
   "source": [
    "Plaintext Inference\n",
    "-------------------\n",
    "\n",
    "- Find accuracy against testing set in plaintext space for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecedd124-bced-4836-bdab-81facc5d604a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = {\n",
    "        \"x\": [],\n",
    "        \"y\": [],\n",
    "    }\n",
    "for i in zip(test_x, test_y):\n",
    "    test_dict[\"x\"].append(np.reshape(i[0], (28,28)))\n",
    "    test_dict[\"y\"].append(i[1])\n",
    "    \n",
    "pi = time.time()\n",
    "y_hats = infer(graph=graph, inputs={key:value for key,value in test_dict.items() if key in [\"x\"]})[\"y_hat\"] \n",
    "pi = time.time() - pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15f6577-df35-49fa-896f-7b2f1199b0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=y_hats[20:40]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cec962-1192-4905-91b5-9663e16c4295",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_sample = test_dict[\"y\"][:20]\n",
    "true_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bff23e7-b5da-4af2-b47a-98b07f0f2c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accurates = np.where(np.isclose(y_hats, test_dict[\"y\"]))\n",
    "len(accurates[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844bc996-4741-45d8-beeb-4357e4be4e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = len(accurates[0])/len(test_dict[\"y\"])\n",
    "print(\"Accuracy {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d74cd47-e200-4371-a9de-854fc032cd3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "current_result = pd.DataFrame({\"accuracy\": [accuracy], \n",
    "                               \"training_time\": [tt], \n",
    "                               \"time_taken\": [pi], \n",
    "                               \"datetime\": [datetime.datetime.now()], \n",
    "                               \"y_hat_sample\": [sample], \n",
    "                               \"y_sample\": [true_sample], \n",
    "                               \"inference_size\": [len(test_dict[\"y\"])],\n",
    "                               \"activation\": [\"Sigmoid\"] if isinstance(graph.nodes(data=True)[\"CNN-RELU\"][\"node\"], Sigmoid) else [\"ReLU\"],\n",
    "                               \"is_plaintext\": [1],\n",
    "                               \"is_cyphertext\": [0],\n",
    "                               \"session\": [session]\n",
    "                              })\n",
    "try:\n",
    "    all_results = pd.read_csv(csv_path, index_col=False)\n",
    "    all_results = all_results.append(current_result)\n",
    "except FileNotFoundError:\n",
    "    all_results = current_result\n",
    "all_results.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a9ec5b-d48d-442b-ae63-6fd60e9db055",
   "metadata": {},
   "source": [
    "Not great, not terrible (3.6 roentgen). Absolute network performance can always be improved by using newer/ better architectures, and more epochs if it has not learnt what it can from the training set. we use a simple 1 CNN layer + 10 Dense layers + softmax into categorical cross entropy, there are much better architectures to use but we are concerned with the encryption here so we dont want to overcomplicate things. This is more of a means to an end of comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f59c1c-cbec-4ce3-bf21-87d0ad1e7663",
   "metadata": {},
   "source": [
    "Encrypted Inference\n",
    "-------------------\n",
    "\n",
    "- find accuracy against testing set again but this time in encrypted space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1c4660-517d-48be-bec4-fe579f0dc385",
   "metadata": {},
   "source": [
    "Parameterise Encoding/ Encryption and Create an Encrypted Generator\n",
    "-------------------------------------------------------------------\n",
    "\n",
    "- Parameterise our neural network graph encryption nodes\n",
    "- Automatically set parameterisation using AtoFHE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70dc7a6-9323-4363-b1e9-4fd92ff59b64",
   "metadata": {},
   "source": [
    "This next cell shows how you would manually define parameters which you would then give to the encryption, decryption, and rotation nodes. However we do not need to do this any more thanks to our new autoHE which automatically parameterises the fully homomorphic nodes of \"concern\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f740fa97-b6a5-49e3-834e-a649b37973df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seal\n",
    "encryption_parameters = {\n",
    "            \"scheme\": seal.scheme_type.CKKS,\n",
    "            \"poly_modulus_degree\": 8192*2,\n",
    "            \"coefficient_modulus\":\n",
    "                [45, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 45],\n",
    "            \"scale\": pow(2.0, 30),\n",
    "            \"cache\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926e1f45-9213-42d0-ac68-c9bc5cf4563e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fhez.nn.parametrisation.autofhe import autoHE # excuse the mixed spelling of parametrisation instead of parameterisation which we use everywhere else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f5efb5-2e32-4ae1-bb44-cbcfc5d0ccf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "encrypted_graph = copy.deepcopy(trained_graph)\n",
    "groups = autoHE(graph=encrypted_graph, nodes=[\"x\"])\n",
    "groups\n",
    "# # Generate Encrypted data peace-meal (as it can get very large)\n",
    "# def row_encrypted_generator(data: np.ndarray, shape: tuple):\n",
    "#     \"\"\"Generate encrypted data of desired shape from rows.\"\"\"\n",
    "#     for row in data:\n",
    "#         row = np.reshape(row, newshape=shape) / 255 # reshape to image shape and normalise between 0-1\n",
    "#         yield ReArray(row, **encryption_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e4ca1f-4b99-4524-8cfe-2031822757ab",
   "metadata": {},
   "source": [
    ".. caution:\n",
    "\n",
    "    This is where your RAM is gonna get swallowed up like Gazrilla in the black-hole at the centre of our universe!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f75b9f5-3a44-41df-b7a6-423ae1180159",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mini_test_dict = {\"x\": test_dict[\"x\"][:10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653474d9-c3a4-4bcc-8e91-8afcc2e01e0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ei = time.time()\n",
    "# y_hats = infer(graph=encrypted_graph, inputs=mini_test_dict)[\"y_hat\"] \n",
    "# ei = time.time() - ei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7171d800-b744-4c9a-996c-bf3c3d0d66c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accurates = np.where(np.isclose(y_hats, test_dict[\"y\"][:len(y_hats)]))\n",
    "# accuracy = len(accurates[0])/len(y_hats)\n",
    "# # save info to csv file we used earlier\n",
    "# current_result = pd.DataFrame({\"accuracy\": [accuracy], \n",
    "#                                \"training_time\": [tt], \n",
    "#                                \"time_taken\": [ei], \n",
    "#                                \"datetime\": [datetime.datetime.now()], \n",
    "#                                \"y_hat_sample\": [y_hats],#[sample], \n",
    "#                                \"y_sample\": [test_dict[\"y\"][:len(y_hats)]], \n",
    "#                                \"inference_size\": [len(y_hats)],\n",
    "#                                \"activation\": [\"Sigmoid\"] if isinstance(graph.nodes(data=True)[\"CNN-RELU\"][\"node\"], Sigmoid) else [\"ReLU\"],\n",
    "#                                \"is_plaintext\": [0],\n",
    "#                                \"is_cyphertext\": [1],\n",
    "#                                \"session\": [session],\n",
    "#                               })\n",
    "# try:\n",
    "#     all_results = pd.read_csv(csv_path, index_col=False)\n",
    "#     all_results = all_results.append(current_result)\n",
    "# except FileNotFoundError:\n",
    "#     all_results = current_result\n",
    "# all_results.to_csv(csv_path, index=False)\n",
    "# all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a047a7b2-98d5-4749-8fe3-f8fed1a569ca",
   "metadata": {},
   "source": [
    "There you have it, encrypted deep learning. Its slow, and heavy (as you would expect), but it works! Now in future we can work on reducing the footprint/ optimisation of FHE + its use. Now go run the top boxes again to plot your new results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
