{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdc69b41-51f3-48f9-89f6-933bd5310157",
   "metadata": {},
   "source": [
    "Fully Homomorphically Encrypted Fashion-MNIST CNN Example\n",
    "=========================================================\n",
    "\n",
    "- This example will download Fashion-MNIST (a drop in replacement for MNIST)\n",
    "- Prepare and encrypt Fashion-MNIST\n",
    "- Train a very basic CNN on Fashion-MNIST\n",
    "- Output some classification of the Fashion-MNIST testing set and calculate its error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8c2f4a-b990-4909-999a-be6545483087",
   "metadata": {},
   "source": [
    "Download Fashion-MNIST\n",
    "----------------------\n",
    "\n",
    "- Get Fashion-MNIST as a zipped up set of CSVs\n",
    "- Unizp Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eabf22f-ba77-470b-a139-f1bad38c26e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f0a8e2-6f34-45d8-935d-d4d1a23a0b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd() # current working directory\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e21c5e-b896-48d1-9808-8c9c0f999581",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(cwd, \"datasets\")\n",
    "if os.path.exists(data_dir):\n",
    "    pass\n",
    "else:\n",
    "    os.mkdir(data_dir)\n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103176f2-a7c4-463e-8403-354db1316d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_zip = os.path.join(data_dir, \"mnist.zip\")\n",
    "if os.path.exists(mnist_zip):\n",
    "    print(\"Skipping mnist download\")\n",
    "else:\n",
    "    print(\"Downloading Fashion-MNIST\")\n",
    "    mnist_url = \"http://nextcloud.deepcypher.me/s/wjLa6YFw8Bcbra9/download\"\n",
    "    r = requests.get(mnist_url, allow_redirects=True, verify=False)\n",
    "    with open(mnist_zip, \"wb\") as f:\n",
    "        f.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4d5a3a-bc16-4f87-b3c7-65524a8a59a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "unzip_dir = os.path.join(data_dir, \"mnist\")\n",
    "if os.path.exists(unzip_dir):\n",
    "    pass\n",
    "else:\n",
    "    os.mkdir(unzip_dir)\n",
    "with zipfile.ZipFile(mnist_zip, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(unzip_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4abd62-426a-4abf-a205-9c5cf1a696ff",
   "metadata": {},
   "source": [
    "\"Wrangle\"/ prepare Fashion-MNIST\n",
    "--------------------------------\n",
    "\n",
    "- Read in the Fashion-MNIST CSVs\n",
    "- Split training and testing features (x) from target (y)\n",
    "- Normalise x and y (in the range 0-1 to prevent infinite numbers when using our approximations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d89550-ef22-4ee0-a041-7e23382f7542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1339b61a-a11c-4123-90ea-47a336535cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = os.path.join(unzip_dir, \"fashion-mnist_train.csv\") \n",
    "test_file = os.path.join(unzip_dir, \"fashion-mnist_test.csv\")\n",
    "train = pd.read_csv(train_file)\n",
    "test = pd.read_csv(train_file)\n",
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48e0390-8ae5-48ad-9fa6-f1aac6c40d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train.iloc[:, 0]\n",
    "train_x = train.iloc[:, 1:]\n",
    "test_x = train.iloc[:, 1:]\n",
    "test_y = test.iloc[:, 0]\n",
    "train_x = train_x.to_numpy()\n",
    "train_y = train_y.to_numpy()\n",
    "test_x = test_x.to_numpy()\n",
    "test_y = test_y.to_numpy()\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7881169-0cf8-4379-968a-ee3eece51ca4",
   "metadata": {},
   "source": [
    "Define Neural Network\n",
    "---------------------\n",
    "\n",
    "- Use [Networkx](https://networkx.org/) to construct a **multi-directed-graph** as a neural network\n",
    "- Nodes for this graph are abstractions of neural network components with forward, backward (backpropogation), update (weight update/ optimisation), and costs (computational depth of traversal to the node)\n",
    "- We use Nodes that inherit from the abstract base class [fhez.nn.graph.node.Node](https://python-fhez.readthedocs.io/en/latest/nodes/node.html#node) so if you need to define your own type of node inherit from this to match the API the network traverser expects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6051a6b2-6348-42b3-99a4-e4fcba385044",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from fhez.nn.graph.io import IO\n",
    "from fhez.nn.operations.cc import CC # Cross Correlation\n",
    "from fhez.nn.operations.sum import Sum\n",
    "from fhez.nn.activation.relu import RELU # Rectified Linear Unit (approximation)\n",
    "from fhez.nn.layer.ann import ANN # Dense/ Artificial Neural Network\n",
    "from fhez.nn.activation.softmax import Softmax\n",
    "from fhez.nn.activation.argmax import Argmax\n",
    "from fhez.nn.loss.cce import CCE # categorical cross entropy\n",
    "\n",
    "from fhez.nn.operations.encrypt import Encrypt\n",
    "from fhez.nn.operations.decrypt import Decrypt\n",
    "from fhez.nn.operations.enqueue import Enqueue\n",
    "from fhez.nn.operations.dequeue import Dequeue\n",
    "from fhez.nn.operations.one_hot_encode import OneHotEncode\n",
    "from fhez.nn.operations.one_hot_decode import OneHotDecode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bbcc64-e827-43d2-bc95-33fbc6179e51",
   "metadata": {},
   "source": [
    "This elipsis section hides my current work around to visualise the network all 'fancy-like', I am working on serialisation of the node objects so pyvis can just pick them up and show us in detail what is going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dae6dd9-2c95-4395-ac9d-7bab2c481b93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pyvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82786c6d-f03f-4743-a524-b581fbd2a405",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "graph = nx.MultiDiGraph()\n",
    "classes = np.array([0,1,2,3,4,5,6,7,8,9])\n",
    "\n",
    "# add nodes to graph with names (for easy human referencing), and objects for what those nodes are\n",
    "graph.add_node(\"x\", group=0)\n",
    "\n",
    "# CONSTRUCT CNN \n",
    "# with intermediary decrypted sum to save on some complexity later\n",
    "graph.add_node(\"CNN-products\", group=1)\n",
    "graph.add_edge(\"x\", \"CNN-products\", weight=CC().cost)\n",
    "graph.add_node(\"CNN-dequeue\", group=1)\n",
    "graph.add_edge(\"CNN-products\", \"CNN-dequeue\", weight=Dequeue().cost)\n",
    "graph.add_node(\"CNN-sum-of-products\", group=1)\n",
    "graph.add_edge(\"CNN-dequeue\", \"CNN-sum-of-products\", weight=Sum().cost)\n",
    "graph.add_node(\"CNN-enqueue\", group=1)\n",
    "graph.add_edge(\"CNN-sum-of-products\", \"CNN-enqueue\", weight=Enqueue().cost)\n",
    "graph.add_node(\"CNN-activation\", group=1)\n",
    "graph.add_edge(\"CNN-enqueue\", \"CNN-activation\", weight=RELU().cost)\n",
    "\n",
    "# CONSTRUCT DENSE FOR EACH CLASS\n",
    "# we want to get the network to regress some prediction one for each class\n",
    "graph.add_node(\"Dense-enqueue\", group=2)\n",
    "for i in classes:\n",
    "    graph.add_node(\"Dense-{}\".format(i), group=2)\n",
    "    graph.add_edge(\"CNN-activation\", \"Dense-{}\".format(i), weight=ANN().cost)\n",
    "    graph.add_node(\"Dense-activation-{}\".format(i), group=2)\n",
    "    graph.add_edge(\"Dense-{}\".format(i), \"Dense-activation-{}\".format(i), weight=RELU().cost)\n",
    "    graph.add_edge(\"Dense-activation-{}\".format(i), \"Dense-enqueue\", weight=Enqueue().cost)\n",
    "    \n",
    "# CONSTRUCT CLASSIFIER\n",
    "# we want to turn the dense outputs into classification probabilities using softmax and how wrong/ right we are using Categorical Cross-Entropy (CCE) as our loss function\n",
    "graph.add_node(\"Softmax\", group=3)\n",
    "graph.add_edge(\"Dense-enqueue\", \"Softmax\", weight=Softmax().cost)\n",
    "graph.add_node(\"Loss-CCE\", group=3)\n",
    "graph.add_edge(\"Softmax\", \"Loss-CCE\", weight=3)\n",
    "graph.add_node(\"One-hot-encoder\", group=0)\n",
    "graph.add_edge(\"One-hot-encoder\", \"Loss-CCE\", weight=0)\n",
    "graph.add_node(\"y\", group=0)\n",
    "graph.add_edge(\"y\", \"One-hot-encoder\", weight=0)\n",
    "\n",
    "\n",
    "graph.add_node(\"Argmax\", group=4)\n",
    "graph.add_edge(\"Dense-enqueue\", \"Argmax\", weight=Argmax().cost)\n",
    "graph.add_node(\"One-hot-decoder\", group=4)\n",
    "graph.add_edge(\"Argmax\", \"One-hot-decoder\", weight=OneHotDecode().cost)\n",
    "graph.add_node(\"y_hat\", group=4)\n",
    "graph.add_edge(\"One-hot-decoder\", \"y_hat\", weight=0)\n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9cbcdd-0a90-4dd1-9128-97d4b36bcf7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "net = Network('700px', '700px', bgcolor='#222222', font_color='white', notebook=True)\n",
    "net.from_nx(graph)\n",
    "# net.show_buttons(filter_=\"physics\")\n",
    "net.show(\"graph.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd81dbb-146d-404e-9b0c-225c8d14d4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = nx.MultiDiGraph()\n",
    "classes = np.array([0,1,2,3,4,5,6,7,8,9])\n",
    "\n",
    "# add nodes to graph with names (for easy human referencing), and objects for what those nodes are\n",
    "graph.add_node(\"x\", group=0, node=IO())\n",
    "\n",
    "# CONSTRUCT CNN \n",
    "# with intermediary decrypted sum to save on some complexity later\n",
    "graph.add_node(\"CNN-products\", group=1, node=CC(weights=(1,6,6), stride=[1,4,4], bias=0))\n",
    "graph.add_edge(\"x\", \"CNN-products\", weight=CC().cost)\n",
    "graph.add_node(\"CNN-dequeue\", group=1, node=Dequeue)\n",
    "graph.add_edge(\"CNN-products\", \"CNN-dequeue\", weight=Dequeue().cost)\n",
    "graph.add_node(\"CNN-sum-of-products\", group=1, node=Sum())\n",
    "graph.add_edge(\"CNN-dequeue\", \"CNN-sum-of-products\", weight=Sum().cost)\n",
    "graph.add_node(\"CNN-enqueue\", group=1, node=Enqueue())\n",
    "graph.add_edge(\"CNN-sum-of-products\", \"CNN-enqueue\", weight=Enqueue().cost)\n",
    "graph.add_node(\"CNN-activation\", group=1, node=RELU)\n",
    "graph.add_edge(\"CNN-enqueue\", \"CNN-activation\", weight=RELU().cost)\n",
    "\n",
    "# CONSTRUCT DENSE FOR EACH CLASS\n",
    "# we want to get the network to regress some prediction one for each class\n",
    "graph.add_node(\"Dense-enqueue\", group=2)\n",
    "for i in classes:\n",
    "    graph.add_node(\"Dense-{}\".format(i), group=2, node=ANN())\n",
    "    graph.add_edge(\"CNN-activation\", \"Dense-{}\".format(i), weight=ANN().cost)\n",
    "    graph.add_node(\"Dense-activation-{}\".format(i), group=2, node=RELU())\n",
    "    graph.add_edge(\"Dense-{}\".format(i), \"Dense-activation-{}\".format(i), weight=RELU().cost)\n",
    "    graph.add_edge(\"Dense-activation-{}\".format(i), \"Dense-enqueue\", weight=Enqueue().cost)\n",
    "    \n",
    "# CONSTRUCT CLASSIFIER\n",
    "# we want to turn the dense outputs into classification probabilities using softmax and how wrong/ right we are using Categorical Cross-Entropy (CCE) as our loss function\n",
    "graph.add_node(\"Softmax\", group=3, node=Softmax())\n",
    "graph.add_edge(\"Dense-enqueue\", \"Softmax\", weight=Softmax().cost)\n",
    "graph.add_node(\"Loss-CCE\", group=3, node=CCE())\n",
    "graph.add_edge(\"Softmax\", \"Loss-CCE\", weight=3)\n",
    "graph.add_node(\"One-hot-encoder\", group=0, node=OneHotEncode())\n",
    "graph.add_edge(\"One-hot-encoder\", \"Loss-CCE\", weight=0)\n",
    "graph.add_node(\"y\", group=0, node=IO())\n",
    "graph.add_edge(\"y\", \"One-hot-encoder\", weight=OneHotEncode().cost)\n",
    "\n",
    "\n",
    "graph.add_node(\"Argmax\", group=4, node=Argmax())\n",
    "graph.add_edge(\"Dense-enqueue\", \"Argmax\", weight=Argmax().cost)\n",
    "graph.add_node(\"One-hot-decoder\", group=4, node=OneHotDecode())\n",
    "graph.add_edge(\"Argmax\", \"One-hot-decoder\", weight=OneHotDecode().cost)\n",
    "graph.add_node(\"y_hat\", group=4, node=IO())\n",
    "graph.add_edge(\"One-hot-decoder\", \"y_hat\", weight=0)\n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d69219-59b3-4855-a1f6-d9cc23120a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "net = Network(notebook=True)\n",
    "net.from_nx(graph)\n",
    "net.show_buttons(filter_=\"physics\")\n",
    "net.show(\"graph.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d1b41d-17fc-4012-bbe7-ea46662a755f",
   "metadata": {},
   "source": [
    "Visualise the graph\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff889ed-60c5-4b4c-b0ec-106ad7fe3556",
   "metadata": {},
   "source": [
    "Visualise the graph using networkx inbuilt plots like spring. This will always be avaliable to you but is fairly rudamentary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80fea31-eb52-4a07-ba03-57129190cc96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nx.draw(graph, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64578f44-9118-49ed-9042-be5d7534c1bc",
   "metadata": {},
   "source": [
    "See my little workaround above for visualising the neural network without node objects. Its super cool and im working on making it work with the node objects included for object inspection!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1c4660-517d-48be-bec4-fe579f0dc385",
   "metadata": {},
   "source": [
    "Parameterise Encoding/ Encryption and Create an Encrypted Generator\n",
    "-------------------------------------------------------------------\n",
    "\n",
    "- Import our encryption library\n",
    "- Parameterise the encryption tailored to the computations we will use\n",
    "- Create a generator that returns encrypted versions of whatever we give it row-by-row (since each image is encoded as a row here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea6ce9a-b9ed-42b4-bb93-9fe31776f488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seal # https://github.com/Huelse/SEAL-Python OR https://github.com/DreamingRaven/python-seal\n",
    "from fhe.nn.layer.cnn import Layer_CNN # from this library\n",
    "from fhe.nn.layer.ann import Layer_ANN # from this library\n",
    "from fhe.rearray import ReArray # meta encryption object from this library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f740fa97-b6a5-49e3-834e-a649b37973df",
   "metadata": {},
   "outputs": [],
   "source": [
    "encryption_parameters = {\n",
    "            \"scheme\": seal.scheme_type.CKKS,\n",
    "            \"poly_modulus_degree\": 8192*2,\n",
    "            \"coefficient_modulus\":\n",
    "                [45, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 45],\n",
    "            \"scale\": pow(2.0, 30),\n",
    "            \"cache\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f5efb5-2e32-4ae1-bb44-cbcfc5d0ccf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Encrypted data peace-meal (as it can get very large)\n",
    "def row_encrypted_generator(data: np.ndarray, shape: tuple):\n",
    "    \"\"\"Generate encrypted data of desired shape from rows.\"\"\"\n",
    "    for row in data:\n",
    "        row = np.reshape(row, newshape=shape) / 255 # reshape to image shape and normalise between 0-1\n",
    "        yield ReArray(row, **encryption_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a89daf0-2be7-4f85-823e-25635a430045",
   "metadata": {},
   "source": [
    "Train Using Encrypted Data\n",
    "--------------------------\n",
    "\n",
    "- Instantiate our neural networks\n",
    "- Call our encrypted data generator to generate data as needed\n",
    "- Compute the forward pass of our neural networks\n",
    "- Compute the backward pass of our neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cce10b9-0882-4218-a92a-196b3d0a206a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = Layer_CNN(weights=( 1, 6, 6 ), stride=[ 1, 4, 4 ], bias=0)\n",
    "dense = None\n",
    "for cyphertext in row_encrypted_generator(data=train_x, shape=( 1, 28, 28 )):\n",
    "    cnn_acti = cnn.forward(cyphertext)\n",
    "    if dense is None:\n",
    "        dense = Layer_ANN(weights=(len(cnn_acti),), bias=0)\n",
    "    dense.forward(cnn_acti)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a877f114-6d83-4590-a835-ca403126ed0e",
   "metadata": {},
   "source": [
    "Test Using Encrypted Data\n",
    "-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f02e846-9715-4a23-9884-e2be77dcb884",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
